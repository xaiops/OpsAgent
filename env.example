# Agent Configuration Environment Variables
# Copy this file to .env and configure your settings

# =============================================================================
# LLM Configuration
# =============================================================================
# Base URL for LLM endpoint (LlamaStack or OpenAI-compatible)
LLM_BASE_URL=https://lss-lss.apps.prod.rhoai.rh-aiservices-bu.com/v1/openai/v1

# API key for LLM authentication (use "not-needed" for LlamaStack)
LLM_API_KEY=not-needed

# Default model name
LLM_DEFAULT_MODEL=llama-4-scout-17b-16e-w4a16

# Model generation parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# =============================================================================
# Memory Store Configuration
# =============================================================================
# Embedding model for semantic search
EMBEDDING_MODEL=text-embedding-3-small

# Embedding vector dimensions
EMBEDDING_DIMS=1536

# =============================================================================
# Prompts Configuration
# =============================================================================
# System prompt template (supports {user_info} and {time} placeholders)
# SYSTEM_PROMPT="You are a helpful assistant..."

# Additional agent instructions
# AGENT_INSTRUCTIONS="- Be helpful and clear..."

# =============================================================================
# Agent Configuration
# =============================================================================
# Agent name
AGENT_NAME=OpsAgent

# Enable debug mode
DEBUG=false

# =============================================================================
# Alternative LLM Providers (Examples)
# =============================================================================
# For Anthropic:
# LLM_BASE_URL=https://api.anthropic.com/v1
# LLM_API_KEY=your-anthropic-api-key
# LLM_DEFAULT_MODEL=claude-3-5-sonnet-20240620

# For OpenAI:
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_API_KEY=your-openai-api-key
# LLM_DEFAULT_MODEL=gpt-4

# =============================================================================
# Optional: Config File Path Override
# =============================================================================
# CONFIG_PATH=/path/to/custom/config.yaml
