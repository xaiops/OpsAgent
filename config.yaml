# Agent Configuration
# This file contains configuration for the LangGraph Ops Agent

# Agent metadata
name: "OpsAgent"
debug: false

# LLM endpoint configuration - LlamaStack integration
llm:
  base_url: "https://lss-lss.apps.prod.rhoai.rh-aiservices-bu.com/v1/openai/v1"
  api_key: "not-needed"  # LlamaStack doesn't require API key
  default_model: "llama-4-scout-17b-16e-w4a16"  # Same as mortgage-agents
  temperature: 0.1  # Low temperature CRITICAL for tool calling!
  max_tokens: 1200  # Match mortgage-agents settings

# Memory store configuration
store:
  embedding_model: "text-embedding-3-small"
  embedding_dims: 1536
  search_limit: 10

# Prompts and instructions
prompts:
  system_prompt: |
    You are an AI assistant with access to Ansible Automation Platform tools.
    Use the available tools to answer user questions about inventories, jobs, hosts, and projects.
  
  agent_instructions: |
    You have 47 tools available from the MCP server. When users ask questions, identify the right tool and use it.
    Always call tools for operational queries - never respond with generic text when real data is available.

# MCP (Model Context Protocol) Servers
mcp:
  enabled: true
  servers:
    aap_ansible:
      name: "Red Hat AAP Ansible"
      url: "http://mcp-aap-ansible-proxy-toolhive-system.apps.virt.na-launch.com/mcp"
      transport: "streamable_http"
      timeout: 30
      retry_attempts: 3
      enabled: true
      description: "Red Hat Ansible Automation Platform - provides ansible, eda, ansible-lint, and documentation tools"
